import chromadb
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer

# Inizializza il modello di embedding locale
embedder = SentenceTransformer("all-MiniLM-L6-v2")

# Funzione di salvataggio in ChromaDB
def store_in_chromadb(nome, estensione, testo, chunk_size=500, overlap=50):
    """
    Divide il testo in chunk, genera embedding locali e li salva in ChromaDB.
    
    Parametri:
    - nome (str): nome del file sorgente
    - estensione (str): formato file (.pdf, .txt, ecc.)
    - testo (str): testo completo del documento
    - chunk_size (int): numero massimo di caratteri per chunk
    - overlap (int): sovrapposizione tra chunk consecutivi
    
    Output:
    - Salva i chunk indicizzati in una collezione ChromaDB
    """

    # 1. Creazione dello splitter di testo
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n\n", "\n", ".", " "]  # Priorità: paragrafo, frase, parola
    )

    # 2. Suddivide il testo in sottosezioni
    chunks = splitter.split_text(testo)

    # 3. Calcola gli embedding per ciascun chunk
    embeddings = embedder.encode(chunks).tolist()

    # 4. Inizializza ChromaDB (database vettoriale)
    client = chromadb.PersistentClient(path="./chroma_db")
    collection = client.get_or_create_collection(name="report_sostenibilita")

    # 5. Genera ID e metadati per ogni chunk
    ids = [f"{nome}_{i}" for i in range(len(chunks))]
    metadatas = [{"origine": nome, "estensione": estensione, "chunk": i} for i in range(len(chunks))]

    # 6. Salva i chunk nel database con embedding e metadati
    collection.add(
        ids=ids,
        documents=chunks,
        embeddings=embeddings,
        metadatas=metadatas
    )

    print(f"✅ Indicizzati {len(chunks)} chunk del documento '{nome}{estensione}' usando embedding locali.")